---

title: "Climate art, hacking Autodesk, and other funemployment projects"
date: 2019-08-28 21:45 UTC
tags: 

---

It's been a great summer. I quit my job in May and have been totally free of obligations for the last few months, until I start a PhD at MIT next week. It's really nice to breathe and reorient before starting up the next mountainâ€”if you have the resources to take time off between endeavors, I'd recommend it.

I spent the first half of the summer traveling in Europe, Asia, and along the West Coast. The last month or so I've been in Cambrige enjoying the nice weather and casually jamming on some projects with friends. So much more fun than a solo project, when you're on the same wavelength! Here are some rough notes on what I've been up to:

## Climate change art

Climate change has been [on](https://twitter.com/geoffreylitt/status/1166363267805171716) [my](https://twitter.com/geoffreylitt/status/1166515258980229122) [mind](https://twitter.com/geoffreylitt/status/1166549545137909762). It's getting harder to look away.

I spent a few days with my friend [Seth](https://seththompson.org/) working on a project for the Climate Fixathon, a monthlong hackathon focused on climate change. We felt a little uneasy with the premise;  what hubris, to think the climate can be "hacked" with software, especially since we only wanted to devote a few days to our project.

So we decided to make a simple art piece, trying to spread the message about climate change in a new way. We wanted to publish something that made the issue feel tangibleâ€”not just the effects, but also the causes.

The result was [HQâ†’CO2](https://hqco2.org/): a site that juxtaposes Street View photos of fossil fuel headquarters with satellite imagery of places affected by climate change. The message is that there are executives in corporate headquartersâ€”real people in buildingsâ€”making billions of dollars selling a product that's ruining the Earth.

![](article_images/august/hqco2.png)

I know that climate change is a complicated problem. Fossil fuels aren't the only cause, and regulating or destroying these companies doesn't magically fix things unless we adjust the rest of our society to not need so many fossil fuels. Still, these companies bear part of the responsibility for this mess we're in, and I think it's right to put pressure on them to be part of the solution.

### The tech

Why do a side project if not to use fancy new tech and over-invest in tools for building the project? ðŸ˜€

Reviews of our tech stack:

[Svelte](https://svelte.dev/): Great concept. Reactive programming is the future, and the compiler is very useful. Fantastic tutorial. I'm curious to see where this framework goes.

WebGL w/ [Regl](https://github.com/regl-project/regl): WebGL opens up endless creative possibilities for web design. Shaders hurt my brain in a good way; they're such a different programming paradigm. I've heard that WebGL has painful boilerplate but Regl makes it easy, which seemed to be true.

[Glitch](https://glitch.com/): We started out the project on Glitch, collaborating in instant realtime Google Docs style. I found the workflow pretty awesome for two people working on a small site, and I'm convinced that live collaboration with integrated hosting is the future of IDEs. There's a lot to figure out to make that experience smooth, but it's so simplifying to have all code shared instantly and live deployed.

We ran into some...glitches with the Glitch VSCode plugin (potentially caused by coffeeshop Wifi) so we ended up reverting to a classic git workflow, which felt familiar but nonetheless a step back from the awesomeness of instant deployment.

[ZEIT](https://zeit.co/home): We deployed on ZEIT, partially because they're one of the hackathon sponsors. I'm still getting used to the serverless architecture and find it a bit overcomplicated at times, but that might just be getting over years of working mostly in Ruby on Rails. We ran into a few annoying hitches that felt like they resulted from too much invisible magic in the deployment process.

On the internal tooling front: I made a system for managing the data on companies and satellite locations in Airtable, and syncing it to our code repo via the Airtable API. Much nicer editing experience than manually editing a giant JSON file of data.

![](article_images/august/airtable.png)

I also made a little tool for tweaking parameters to Google Maps API requests and seeing the results in realtime, which was super helpful for fine tuning the imagery with a fast feedback loop.

<video controls="controls" preload="auto" muted="muted" data-video="0" type="video/mp4" src="/images/article_images/august/map.m4v" width="100%"></video>

Other climate related things:

I signed up for [Project Wren](https://projectwren.com/), which helps you calculate your carbon footprint and buy high-quality carbon offsets. I'd recommend checking them out. 

If you have ideas on how software can help address climate change, shoot me an [email](mailto:gklitt@gmail.com) or [tweet](https://twitter.com/geoffreylitt), I'd love to hear from you. I'm hoping I can partially orient my PhD research towards this topic at some point.

Also, I just gotta say: years of professional software engineering has trained me to work sustainably, but there's something to be said for a few long, unsustainable days of furious programming. Early-stage creative prototyping seems to benefit from a certain energy level that's not easily attainable in a sustainable environment.

## Adventures in computer vision

My friend [Kevin](https://kevinlynagh.com/) has a CNC machine with a webcam pointed at it. This seemed like an interesting jumping off point for some experiments with using computer vision to help with fabrication.

We started by trying to use Python and OpenCV to automatically recognize the corners of rectangular objects. Our first demo was finding the corners of an index card taped to some cardboard. In this screenshot you can see the stages of the pipeline. Clockwise from top left:

- Input image (in black and white)
- Apply slight blur
- Detect edges with Canny edge detection
- Detect lines with Hough line transform
- Plot detected corners of the index card (intersections of lines) in a transformed coordinate space

![](article_images/august/opencv.png)

This was fun but was quite finicky to get working reliably, so we pivoted to a new task. The idea was to display live video from the CNC bed *inside* CAD software, at correct scale, to help understand how objects in the CAD design correspond to the real world fabrication surface. This involved learning a lot, lot more about Win32 COM and VBScript than I ever expected to.

Step 1: get live video displaying in Autodesk Inventor! The workflow was pretty janky:

* Mac host machine writes images from webcam out to file
* filesystem is shared with Windows guest VM
* Python script on Windows VM tells Autodesk to update image based on new file contents

Seeing this working the first time was thrilling:

<video controls="controls" preload="auto" muted="muted" data-video="0" type="video/mp4" src="/images/article_images/august/autodesk.m4v" width="100%"></video>

Step 2: user selects the corners of a known rectangular area in the image using CAD software. program reads out the corner positions from the CAD software. Pro tip: when sending coordinates between multiple programs, spend some time understand the coordinate systems of the various programs before you start! Also, why can't everyone just agree on which corner is 0, 0?

In the image below you can see the corners selected with purple crosses:

![](article_images/august/corners.png)

Step 3: Using the selected corners, do a perspective transform to create an image that looks like an "overhead" view of the rectangular area, scaled to the physical coordinates in the CAD software. Here we're using Autodesk to measure some calipers set to 2 inches. The software measurement turned out pretty accurate!

![](article_images/august/calipers.png)

Quick overall impressions:

The OpenCV API is really fun for amateurs. It provides powerful built-in functions, but still lets you flexibly compose your own pipelines, unlike lots of neural net based tools.

The Windows COM system has some rough patches, but I was amazed by how much power we had to query and control every single object in the Autodesk system. It felt way more direct than the web APIs I'm used to using to extend systems. Is all Windows software this extensible?? (I'm guessing not)

## Other explorations

I started a couple other projects that are still in very early days, and may continue developing if I have time:

My friend [Eli](https://reallyeli.com/) and I spent a couple days hacking on a UI for exploring math expressions. We ended up with a textbox where you can type in arithmetic, and a UI to hover over any sub-expression and see the result of that sub-expression. (partly inspired by my friend Glen's awesome project, [Legible Mathematics](http://glench.com/LegibleMathematics/))

<video controls="controls" preload="auto" muted="muted" data-video="0" type="video/mp4" src="/images/article_images/august/arithmetic.m4v" width="100%"></video>

It was my first time building something in Elmâ€”pairing with friends who know other languages is a fantastic way to learn. Elm was such a good fit for this problem that I found myself repeatedly in awe. Check out [the parser code](https://github.com/erose/structured-editor/blob/master/src/Editor.elm#L98): so beautiful!

I'm interested in eventually growing this into some sort of structured code editor. It'll be particularly interesting to try combining the input and output boxes and make the interaction feel intuitive.

I've also been exploring some early prototypes which I plan to eventually grow into a fuller research project on end user programming.

One concept I'm exploring is a UI for transforming nested JSON objects with live feedback. What does a good formula language look like for this sort of task when it's coupled to an environment that shows the data?

<video controls="controls" preload="auto" muted="muted" data-video="0" type="video/mp4" src="/images/article_images/august/jsonsheets.m4v" width="100%"></video>

Another kinda related idea I'm exploring is a visual environment for making interactive UIs based on reactive streams (building on tools like [RxJS](https://rxjs-dev.firebaseapp.com/) and [RxMarbles](https://rxmarbles.com/)). I've come across a fair amount of work on writing reactive UIs in code, and visualizing reactive code, but haven't seen much on actually *creating* the reactive code in a visual environment in the first place.

This is a super rough screenshot of a prototype I'm mocking up, where you can see streams and visually manipulate them to create a UI. On the left is a mobile app UI, on the right are a series of streams being derived from a stream of click events, all defined with a functional formula language in something like a spreadsheet formula editor. Still very early but I'm excited about the potential.

![](article_images/august/reactive.png)

If you have thoughts about any of these ideas, I'd love to chatâ€”send me an [email](mailto:gklitt@gmail.com) or [tweet](https://twitter.com/geoffreylitt)!

Also, now that I'm doing research full time at MIT, I'm planning to post roughly monthly updates about my work here. If you're interested, you can follow along via [Twitter](https://twitter.com/geoffreylitt) or [RSS.](/feed.xml)